{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f6dc3a-8e1d-45f4-8fbd-0b8815fccbaf",
   "metadata": {},
   "source": [
    "# Particle filtering for inference\n",
    "\n",
    "Here, we try to put it all together to infer $\\mathbf{v}$ from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21effa2d-69a0-4f20-91d7-7c7dc82c2715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(12345)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    'text.latex.preamble': '\\\\usepackage{amsmath}\\\\usepackage{amssymb}'\n",
    "})\n",
    "\n",
    "import scipy.stats as stats\n",
    "from functools import partial\n",
    "\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import jax.random as jr\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap\n",
    "from jax.scipy.special import logsumexp\n",
    "\n",
    "init_key = jr.key(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1915b595-0ee7-4542-854a-5f4753f51c78",
   "metadata": {},
   "source": [
    "## Make some synthetic data\n",
    "\n",
    "(copied over from `gen_synthetic_data.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed78ab8-5195-4188-a182-5994001ccf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_freq = 250  # maximum (absolute value) frequency we care about\n",
    "Nlat = 3  # number of latent patterns\n",
    "N = 1000  # number of samples\n",
    "dt = 0.001  # sample spacing (in s)\n",
    "\n",
    "taxis = np.arange(0, N * dt, dt)\n",
    "freqs = np.fft.fftshift(np.fft.fftfreq(N, dt))\n",
    "Omega = freqs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f2a02-282b-4018-9ef6-ca3d0bd0fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_freqs = [5, 25, 60]  # peak power frequencies of each latent\n",
    "center_std = [.1, .5, 1.5]\n",
    "\n",
    "all_v = []\n",
    "for mu, sig in zip(center_freqs, center_std):\n",
    "    right = stats.norm.pdf(freqs, loc=mu, scale=sig)\n",
    "    left = stats.norm.pdf(freqs, loc=-mu, scale=sig)\n",
    "    this_v = right + left\n",
    "    this_v /= np.linalg.norm(this_v)\n",
    "    all_v.append(this_v)\n",
    "\n",
    "v = np.stack(all_v, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9b9bc6-d2c1-4ae5-9182-ad406dcc7e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = np.fft.ifftshift(v, axes=1)\n",
    "s = np.fft.ifft(vv)\n",
    "s = np.real(s)  # real parts should be very near 0\n",
    "\n",
    "# make D\n",
    "Nchan = 5\n",
    "D = np.random.randn(Nchan, Nlat)\n",
    "D /= np.linalg.norm(D, axis=0)\n",
    "\n",
    "# make x\n",
    "eps = 1e-4\n",
    "x = D @ s\n",
    "x += eps * np.random.randn(*x.shape)\n",
    "\n",
    "# plot it\n",
    "scale_factor = 0.01\n",
    "plt.plot(taxis, (x + scale_factor * np.arange(Nchan)[:, np.newaxis]).T);\n",
    "plt.title(r\"Data $\\mathbf{X}$\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Channel\")\n",
    "plt.gca().set_yticks(scale_factor * np.arange(Nchan));\n",
    "plt.gca().set_yticklabels(range(Nchan));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba801bfa-a663-49c7-b501-f5e7f0704920",
   "metadata": {},
   "source": [
    "## Define some functions for inference\n",
    "\n",
    "(copied over from `v_sampling.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dcecd9-3ca4-44f1-835b-ed99cf078729",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def phi(t, freqs):\n",
    "    \"\"\"\n",
    "    Calculate phi_t as in notes. \n",
    "    Assumes \\omega = 0 is at index 0!\n",
    "    \"\"\"\n",
    "    phase = jnp.exp(1j * 2 * jnp.pi * freqs * t) \n",
    "    mask = jnp.abs(freqs) > 0\n",
    "    phase *= mask\n",
    "    phase /= jnp.sqrt(freqs.shape[0] - 1)\n",
    "    return phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b1806-e062-41cc-bc3b-4caf4c5625c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jit, static_argnums=(3, 4))\n",
    "def calc_vhat(vprev, bt, t, Omega, dt):\n",
    "    \"\"\"\n",
    "    vprev = v_{t-1}\n",
    "    bt    = \\hat{m}_t/f_t\n",
    "    t     = time\n",
    "    Omega = number of frequencies\n",
    "    \"\"\"\n",
    "    freqs = jnp.fft.fftfreq(Omega, dt)\n",
    "    phit = phi(t, freqs)\n",
    "    alpha = jnp.dot(vprev, phit)\n",
    "    oo = Omega/np.sqrt(Omega - 1)\n",
    "    lam = -jnp.conj(alpha) + oo * bt * jnp.sqrt((1 - jnp.abs(alpha)**2)/(1 - (oo * bt)**2))\n",
    "    \n",
    "    vv = (vprev + jnp.conj(lam * phit))/jnp.sqrt(1 + jnp.abs(lam)**2 + 2 * jnp.real(lam * alpha))\n",
    "    \n",
    "    return vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a255dd-4e9a-444c-a24a-2783b67d36c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def vMF_real2cplx(v):\n",
    "    \"\"\"\n",
    "    Transform a N-vector draw from a vMF into v with \n",
    "    v^*{-omega} = v_{omega} (i.e., spectrum of a real signal).\n",
    "    Assumes frequency 0 is also index 0!!!\n",
    "    \"\"\"\n",
    "    vv = jnp.empty(v.shape, dtype='complex64')\n",
    "    N = v.shape[0]\n",
    "    mid = (N + 1)//2\n",
    "\n",
    "    vv = vv.at[:mid].set(v[:mid])\n",
    "    \n",
    "    if N % 2 == 0:\n",
    "        vv = vv.at[:mid].add(1j * v[mid:])\n",
    "        vv = vv.at[-1:mid:-1].set(jnp.conj(vv[1:mid]))\n",
    "        vv = vv.at[mid].set(jnp.conj(vv[0]))\n",
    "        # vv[:mid] = v[:mid]\n",
    "        # vv[:mid] += 1j * v[mid:]\n",
    "        # vv[-1:mid:-1] = jnp.conj(vv[1:mid])\n",
    "        # vv[mid] = jnp.conj(vv[0])\n",
    "    else:\n",
    "        vv = vv.at[1:mid].add(1j * v[mid:])\n",
    "        vv = vv.at[-1:(mid - 1):-1].set(jnp.conj(vv[1:mid]))\n",
    "        # vv[:mid] = v[:mid]\n",
    "        # vv[1:mid] += 1j * v[mid:]\n",
    "        # vv[-1:(mid - 1):-1] = jnp.conj(vv[1:mid])\n",
    "        \n",
    "    return vv/jnp.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea280e-3743-4d4b-99f8-a3a78dbd4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def vMF_cplx2real(v):\n",
    "    \"\"\"\n",
    "    Transform a N-vector complex spectrum v with \n",
    "    v^*{-omega} = v_{omega} (i.e., spectrum of a real signal)\n",
    "    to a real vector with real parts up front and imaginary parts in back.\n",
    "    Assumes frequency 0 is also index 0!!!\n",
    "    \"\"\"\n",
    "    vv = jnp.empty(v.shape, dtype=jnp.float32)\n",
    "    N = v.shape[0]\n",
    "    mid = (N + 1)//2\n",
    "\n",
    "    vv = vv.at[:mid].set(jnp.real(v[:mid]))\n",
    "    \n",
    "    if N % 2 == 0:\n",
    "        vv = vv.at[mid:].set(jnp.imag(v[:mid]))\n",
    "        # vv[:mid] = jnp.real(v[:mid])\n",
    "        # vv[mid:] = jnp.imag(v[:mid])\n",
    "    else:\n",
    "        vv = vv.at[mid:].set(jnp.imag(v[1:mid]))\n",
    "        # vv[:mid] = jnp.real(v[:mid])\n",
    "        # vv[mid:] = jnp.imag(v[1:mid])\n",
    "    return vv * jnp.sqrt(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4354bfa6-7273-4128-b89d-96604655796d",
   "metadata": {},
   "source": [
    "## Set up inference\n",
    "\n",
    "Calculate some quantities that we'll need later.\n",
    "\n",
    "In the notes, we want to solve $\\min \\lVert \\mathbf{X} - \\mathbf{DM}\\rVert_F$ for $\\mathbf{M}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6068f-03fe-48aa-a3f2-bb390991bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284b654-cba3-4118-95a2-2f9a535023d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.linalg.lstsq(D, x)[0]\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab18797-653f-471d-9944-45f24450106c",
   "metadata": {},
   "source": [
    "In the data above, we have assumed $f_{jt} = 1$, so we won't worry about that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe826a-ce22-4f5b-9494-44cfe2aac0fb",
   "metadata": {},
   "source": [
    "## Do particle filtering\n",
    "\n",
    "The goal is not to make it fast, just to test for whether we can recover $\\mathbf{v}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375a1530-af15-4bf6-9d62-2f2ac44b2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100  # number of particles\n",
    "kappa = jnp.array(10. * Omega)  # for transition\n",
    "kappa_p = kappa / 100  # for proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47263c8d-9156-4aba-ad30-16e11e9e1a47",
   "metadata": {},
   "source": [
    "We want to calculate weights. Initially:\n",
    "$$\n",
    "\\log \\tilde{w}_j = \\log \\mu(\\mathbf{V}_j) + \\log g(\\mathbf{x}_0|\\mathbf{V}_j) - \\log q(\\mathbf{V}_j|\\mathbf{x}_0)\n",
    "$$\n",
    "where the terms are the prior, emission, and proposal distribution, respectively, and $\\mathbf{V}_j$ is the $j$th particle sample of $\\mathbf{v}$ at $t=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb43975-2b55-49b6-9748-a2ae1b827976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vmf_dist(vprev, kappa, calc_vhat, M):\n",
    "    \"\"\"\n",
    "    Calculate the proposal distribution and return a sampleable \n",
    "    distribution object. \n",
    "    vprev is the *complex* representation of v\n",
    "    vhat is a function that operates \n",
    "    \"\"\"\n",
    "    K, L, Omega = vprev.shape\n",
    "    vhat = np.empty_like(vprev)\n",
    "    mu = np.empty(vprev.shape, dtype='float32')\n",
    "\n",
    "    for k in range(K):\n",
    "        for l in range(Nlat):\n",
    "            vhat[k, l] = calc_vhat(vprev[k, l], M[l])\n",
    "            mu[k, l] = vMF_cplx2real(vhat[k, l])\n",
    "            mu[k, l] /= np.linalg.norm(mu[k, l])  # shouldn't be necessary, but roundoff?\n",
    "\n",
    "    return tfd.VonMisesFisher(mu, kappa)\n",
    "\n",
    "def get_v_samples(vmf, key):\n",
    "    vmf_s = vmf.sample((), sample_key)\n",
    "\n",
    "    v_s = np.empty(vmf_s.shape, dtype='complex128')\n",
    "    for k in range(vmf_s.shape[0]):\n",
    "        for l in range(vmf_s.shape[1]):\n",
    "            v_s[k, l] = vMF_real2cplx(vmf_s[k, l])\n",
    "\n",
    "    return vmf_s, v_s\n",
    "\n",
    "def get_data_pred(v_s, D, t):\n",
    "    st = np.fft.ifft(v_s)\n",
    "    st = np.real(st)\n",
    "    xbar = (D @ st)[:, :, t]\n",
    "    return xbar\n",
    "\n",
    "def resample(logw):\n",
    "    \"\"\"\n",
    "    Given a set of logged weights, return a set of indices corresponding to particles \n",
    "    from which the resampled weights are drawn. That is, if X are the samples, then\n",
    "    X[resample(logw)] are the new particles, each with weight 1/len(logw).\n",
    "    This implements Systematic Resampling as detailed in the Doucet review.\n",
    "    \"\"\"\n",
    "    K = len(logw)\n",
    "    # make a log cdf\n",
    "    aa = np.tile(logw, (len(logw), 1))\n",
    "    aa[np.triu_indices(K)] = -np.inf\n",
    "    log_cdf = logsumexp(aa, 1)\n",
    "\n",
    "    U = (np.arange(1, K + 1) - 1)/K\n",
    "    U += np.random.rand()/K\n",
    "\n",
    "    return np.digitize(np.log(U), log_cdf) - 1\n",
    "\n",
    "def resample_if_needed(logw, thresh):\n",
    "    log_ESS = -logsumexp(2 * logw)\n",
    "\n",
    "    if log_ESS < np.log(K) + np.log(thresh):\n",
    "        do_resample = True\n",
    "    else:\n",
    "        do_resample = False\n",
    "\n",
    "    if do_resample:\n",
    "        inds = resample(logw)\n",
    "    \n",
    "        logw = -np.log(K) * np.ones(K)\n",
    "    else:\n",
    "        inds = range(len(logw))\n",
    "\n",
    "    return inds, logw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16377f-2ac2-4e08-bb24-a48844da651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate initial guess for v\n",
    "# assume \"previous\" v is white noise\n",
    "vmfprev = jnp.ones(Omega)\n",
    "vmfprev /= jnp.linalg.norm(vmfprev)\n",
    "vprev = vMF_real2cplx(vmfprev)\n",
    "vprev = vprev * (jnp.abs(freqs) > 0)  # no zero-frequency\n",
    "\n",
    "v_s = jnp.tile(vprev, (K, Nlat, 1))\n",
    "vmf_s = jnp.tile(vmfprev, (K, Nlat, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb55f77-34b4-4bc3-a25d-61fc42553a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "key, sample_key = jr.split(init_key)\n",
    "\n",
    "for (tidx, t) in enumerate(jnp.arange(0, 0.02, dt)):\n",
    "    vprev = v_s\n",
    "    vmfprev = vmf_s\n",
    "    \n",
    "    vhat_t = lambda x, y: calc_vhat(x, y, t, Omega, dt)\n",
    "    vmf = get_vmf_dist(vprev, kappa_p, vhat_t, M[:, tidx])\n",
    "    \n",
    "    # sample based on vhat\n",
    "    key, sample_key = jr.split(key)\n",
    "    vmf_s, v_s = get_v_samples(vmf, sample_key)\n",
    "    \n",
    "    # get data prediction for this time\n",
    "    xbar = get_data_pred(v_s, D, tidx)\n",
    "\n",
    "    # term 1: transition\n",
    "    # assume our transition is determined by mu = vprev above and kappa_t\n",
    "    if t == 0:\n",
    "        trans = tfd.VonMisesFisher(vmfprev, 0.)\n",
    "    else:\n",
    "        trans = tfd.VonMisesFisher(vmfprev, kappa)\n",
    "    logw = trans.log_prob(vmf_s).sum(axis=-1)\n",
    "    \n",
    "    # term 2: emission\n",
    "    # assume multivariate normal with mean xbar and std eps\n",
    "    emissions = tfd.Normal(xbar.astype('float32'), eps)\n",
    "    logw += emissions.log_prob(x[:, tidx]).sum(axis=-1)\n",
    "    \n",
    "    # term 3: proposal\n",
    "    # as above, distribution is vMF(mu, kappa)\n",
    "    logw -= vmf.log_prob(vmf_s).sum(axis=-1)\n",
    "    \n",
    "    # normalize\n",
    "    logw -= logsumexp(logw)\n",
    "\n",
    "    # resample if needed\n",
    "    inds, logw = resample_if_needed(logw, 0.8)\n",
    "    v_s = v_s[inds]\n",
    "    vmf_s = vmf_s[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa983c1-2133-4795-9622-dff0e14043cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_mean = np.einsum('k,klt', np.exp(logw), v_s)\n",
    "plt.plot(np.real(v_mean).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701992ef-68c2-4161-9a47-7f584027c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.imag(v_s)[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa18c31c-87e2-42ab-8e19-63e61d933425",
   "metadata": {},
   "outputs": [],
   "source": [
    "logw.shape, v_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61c3a2-2d8f-49b6-a25c-5b609dd46bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
